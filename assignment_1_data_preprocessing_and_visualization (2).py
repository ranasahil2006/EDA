# -*- coding: utf-8 -*-
"""Assignment 1: Data Preprocessing and Visualization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11Iy35NUNx1UsbV9mT0FMhlhjyDjxnrxF

Suppose the data for analysis includes the attribute Tree height with the following values:
4.3, 2.5, 2.5, 2.2, 7.9, 5.4, 6.3, 4.8, 4.0, 4.0, 4.2, 7.9, 13.4, 8.4, 5.8, 5.5, 5.5, 5.5, 2.7, 6.5
1. Give the five-number summary for the data.
2. Show a box plot of the data.
3. Partition the given data into 4 bins using
 Equal frequency partitioning
 Equal width partitioning
4. How would you determine the outliers in this data?
5. Consider the following data:
4.3, 2.5, 2.5, ?, ?, 5.4, 6.3, ?, 4.0, 4.0, ?, ?, 13.4, 8.4, ?, 5.5, 5.5, 5.5, 2.7, 6.5
Handle the missing values by two different ways
"""

import numpy as np

tree_heights = [4.3, 2.5, 2.5, 2.2, 7.9, 5.4, 6.3, 4.8, 4.0, 4.0, 4.2, 7.9, 13.4, 8.4, 5.8, 5.5, 5.5, 5.5, 2.7, 6.5]
minimum = np.min(tree_heights)
q1 = np.percentile(tree_heights, 25)
median = np.median(tree_heights)
q3 = np.percentile(tree_heights, 75)
maximum = np.max(tree_heights)

print(f"Minimum: {minimum}")
print(f"Q1 (25th percentile): {q1}")
print(f"Median (50th percentile): {median}")
print(f"Q3 (75th percentile): {q3}")
print(f"Maximum: {maximum}")

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.boxplot(tree_heights, vert=False, patch_artist=True, boxprops=dict(facecolor='lightblue'))

plt.title("Box Plot of Tree Heights")
plt.xlabel("Tree Heights")

plt.show

"""**Equal Frequency Binning:**

number of terms = 20

bins = 4

terms in each bin = 20/4 = 5

ordered data: 2.2, 2.5, 2.5, 2.7, 4.0, 4.0, 4.2, 4.3, 4.8, 5.4, 5.5, 5.5, 5.5, 5.8, 6.3, 6.5, 7.9, 7.9, 8.4, 13.4

bin 1: [2.2, 2.5, 2.5, 2.7, 4.0]

bin 2: [4.0, 4.2, 4.3, 4.8, 5.4]

bin 3: [5.5, 5.5, 5.5, 5.8, 6.3]

bin 4: [6.5, 7.9, 7.9, 8.4, 13.4]

**Equal Width Binning:**
Range of each bin = minimum + nW where n is the number of bin and W is the range of each bin.

W= (13.4-2.2)/4 = 2.8

range for bin 1: 5

range for bin 2: 7.8

range for bin 3: 10.6

range for bin 4: 13.4

bin 1: [2.2, 2.5, 2.5, 2.7, 4.0, 4.0, 4.2, 4.3, 4.8]

bin 2: [5.4, 5.5, 5.5, 5.5, 5.8, 6.3, 6.5]

bin 3: [7.9, 7.9, 8.4]

bin 4: [13.4]

The marks of the students in the final exam are
[56.7, 45, 65, 77, 75, 78, 56, 73, 75, 24, 0, 10, 100, 95, 45, 52, 65, 66, 58, 58.5, 59, 61].

Using any programming language calculate some basics statistics of the given data.

(a) Calculate the mean, median, mode, 5% and 10% trimmed mean of the given data. What do you think is a better measure of centrality? Which one is more robust?

(b) Create a list of random numbers with uniform distribution between 1 and 5 and calculate the statistics you calculated in part(a). Comment on the values you found.
"""

import numpy as np
from scipy import stats

exam_data = [56.7, 45, 65, 77, 75, 78, 56, 73, 75, 24, 0, 10, 100, 95, 45, 52, 65, 66, 58, 58.5, 59, 61]

mean = round(np.mean(exam_data), 1)
median = np.median(exam_data)
mode = stats.mode(exam_data)

trimmedfive = round(stats.trim_mean(exam_data, 0.05), 1)
trimmedten = round(stats.trim_mean(exam_data, 0.1), 1)

print(f"Mean: {mean}")
print(f"Median: {median}")
print(f"Mode: {mode}")
print(f"5% Trimmed Mean: {trimmedfive}")
print(f"10% Trimmed Mean: {trimmedten}")

import numpy as np
from scipy import stats

random_numbers = np.random.uniform(low=1, high=5, size=20)

mean = round(np.mean(random_numbers), 1)
median = round(np.median(random_numbers), 1)
mode_result = stats.mode(random_numbers)
mode_value = mode_result.mode
mode= round(mode_value, 1)

trimmedfive = round(stats.trim_mean(random_numbers, 0.05), 1)
trimmedten = round(stats.trim_mean(random_numbers, 0.1), 1)

print(f"Mean: {mean}")
print(f"Median: {median}")
print(f"Mode: {mode}")
print(f"5% Trimmed Mean: {trimmedfive}")
print(f"10% Trimmed Mean: {trimmedten}")

"""**problem 3**"""

from google.colab import drive
import pandas as pd

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.names'

with open(path, 'r') as f:
  print(f.read())

from google.colab import drive
import pandas as pd
import numpy as np
from scipy import stats

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

age_df = df['age']

mean = round(np.mean(age_df), 1)

print(f"Mean: {mean}")

from google.colab import drive
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

frequency = df['native-country'].value_counts()

frequency.plot(kind='bar')

plt.title("Frequency of Native Country")
plt.xlabel("Native Country")
plt.ylabel("Frequency")

plt.show()

from google.colab import drive
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

drive.mount('/content/drive')
path= '/content/drive/MyDrive/forestfires.csv'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

df.replace(['?', 'NA', '-', ''], np.nan, inplace=True)

print(df.isnull().sum())

from google.colab import drive
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

plt.figure(figsize=(12, 8))
df['age'].hist(bins=10)
plt.title(f'Histogram of Age with 10 bins')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

from google.colab import drive
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

mean_values = df.mean(numeric_only=True)
std_dev_values = df.std(numeric_only=True)
mean_values = round(mean_values, 1)
std_dev_values = round(std_dev_values, 1)

print("Mean Values:")
print(mean_values)
print("\nStandard Deviation Values:")
print(std_dev_values)

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

plt.figure(figsize=(10, 6))
sns.boxplot(x='sex', y='age', data=df)
plt.title('Boxplots of Age against Sex')
plt.xlabel('Sex')
plt.ylabel('Age')
plt.show()

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

table = pd.crosstab(df['age'], df['sex'], margins=True, margins_name="Total")
print(table)

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

numeric_columns = df.select_dtypes(include='number')
print(numeric_columns)

cov_matrix = numeric_columns.cov()
rounded = cov_matrix.round(2)
table = rounded.to_latex()
print(table)

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

plt.figure(figsize=(8, 6))
sns.heatmap(rounded, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={"size": 6})


plt.title('Covariance Matrix Heatmap')
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.show()

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import itertools

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns

for col1, col2 in itertools.combinations(numeric_columns, 2):
    plt.figure(figsize=(10, 8))
    heatmap_data = pd.crosstab(df[col1], df[col2])
    sns.heatmap(heatmap_data, cmap="YlGnBu")
    plt.title(f'Heatmap of {col1} vs {col2}')
    plt.xlabel(col2)
    plt.ylabel(col1)
    plt.show()

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import itertools

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

    # Scatter plot
plt.figure(figsize=(19, 12))
sns.scatterplot(data=df, x='hours-per-week', y='education')
plt.title('Scatter Plot of education vs hours-per-week')
plt.xlabel('hours-per-week')
plt.ylabel('education')
plt.show()

    # Line graph
plt.figure(figsize=(19, 12))
sns.lineplot(data=df, x='hours-per-week', y='education')
plt.title('Line Graph of education vs hours-per-week')
plt.xlabel('hours-per-week')
plt.ylabel('education')
plt.show()

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import itertools
from sklearn.preprocessing import StandardScaler, MinMaxScaler

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
scaler = MinMaxScaler()
df_normalized = pd.DataFrame(scaler.fit_transform(df[numeric_columns]), columns=numeric_columns)

    # Scatter plot
plt.figure(figsize=(12, 6))
sns.scatterplot(data=df_normalized, x='hours-per-week', y='education-num')
plt.title(f'Scatter Plot of education-num vs hours-per-week')
plt.xlabel('hours-per-week')
plt.ylabel('education-num')
plt.show()

    # Line graph
plt.figure(figsize=(12, 6))
sns.lineplot(data=df_normalized, x='hours-per-week', y='education-num')
plt.title(f'Line Graph of education-num vs hours-per-week')
plt.xlabel('hours-per-week')
plt.ylabel('education-num')
plt.show()

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import itertools
from sklearn.preprocessing import StandardScaler, MinMaxScaler

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
scaler = MinMaxScaler()
df_normalized = pd.DataFrame(scaler.fit_transform(df[numeric_columns]), columns=numeric_columns)

plt.figure(figsize=(12, 8))
df['age'].hist(bins=10)
plt.title(f'Histogram of Age with 10 bins Without any scaling')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import itertools
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from scipy.spatial.distance import pdist, squareform

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
scaler = MinMaxScaler()
df_normalized = pd.DataFrame(scaler.fit_transform(df[numeric_columns]), columns=numeric_columns)

numeric_data = df[numeric_columns].values

l2_distances = pdist(numeric_data, metric='euclidean')

l2_distance_matrix = squareform(l2_distances)

l2_distance_df = pd.DataFrame(l2_distance_matrix, index=numeric_columns, columns=numeric_columns)

plt.figure(figsize=(12, 10))
sns.heatmap(l2_distance_df, annot=True, cmap='coolwarm', xtick_rotation=45, ytick_rotation=45)
plt.title('Heatmap of L2 Distances between Numeric Attributes')
plt.show()

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import itertools
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from scipy.spatial.distance import pdist, squareform

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

num_rows, num_column = df.shape

print(f"Number of rows: {num_rows}")
print(f"Number of columns: {num_column}")

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import itertools
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from scipy.spatial.distance import pdist, squareform

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

Q1 = df['hours-per-week'].quantile(0.25)
Q3 = df['hours-per-week'].quantile(0.75)

IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers = df[(df['hours-per-week'] < lower_bound) | (df['hours-per-week'] > upper_bound)]

print("Outliers detected using IQR method:")
print(outliers)

from google.colab import drive
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
import itertools
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from scipy.spatial.distance import pdist, squareform
from scipy import stats

drive.mount('/content/drive')
path= '/content/drive/MyDrive/adult/adult.data'

names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
         'marital-status', 'occupation', 'relationship', 'race', 'sex',
         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']

df = pd.read_csv(path, header=None, names=names)

Q1 = df['hours-per-week'].quantile(0.25)
Q3 = df['hours-per-week'].quantile(0.75)

IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

df_no_outliers = df[(df['hours-per-week'] >= lower_bound) & (df['hours-per-week'] <= upper_bound)]

age_df = df_no_outliers['hours-per-week']

minimum = np.min(age_df)
q1 = np.percentile(age_df, 25)
median = np.median(age_df)
q3 = np.percentile(age_df, 75)
maximum = np.max(age_df)
mode_result = stats.mode(age_df)
mode_value = mode_result.mode
mode= round(mode_value, 1)
mean = round(np.mean(age_df), 1)

print(f"Minimum: {minimum}")
print(f"Q1 (25th percentile): {q1}")
print(f"Median (50th percentile): {median}")
print(f"Q3 (75th percentile): {q3}")
print(f"Maximum: {maximum}")
print(f"Mode: {mode}")
print(f"Mean: {mean}")